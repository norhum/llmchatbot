The tests and the dev set are both at 2.38, so so far so good. Let's try to decrease the learning rate by a factor of 10 and train for another 50,000 iterations. We would hope to beat 2.32, but we are doing this haphazardly. I don't have confidence that our learning rate or learning rate decay is set very well. The optimization here is suspect, and this isn't how you would typically do it in production. In production, you would create parameters or hyper parameters out of all these settings. Then, you would run lots of experiments to see which ones are working well. Okay, so we have 2.17 now and 2.2. You see how the training and validation performance are starting to slowly depart? Maybe we're getting the sense that the neural net is good enough or that the number of parameters is large enough that we are slowly starting to overfit. Let’s run one more iteration and see where we get. You would be running lots of experiments and then scrutinizing which ones give you the best dev performance. Once you find the hyper parameters that make your dev performance good, you evaluate the test set performance a single time. That’s the number that you report in your paper. Let's rerun the plot, train, and dev. Because we're getting lower loss, it's likely the embedding size was holding us back. Okay, so we’re roughly getting 2.16 and 2.19. There are many ways to go from here. We can continue tuning the optimization, playing with the sizes of the neural net, or increasing the number of words or characters we take as input. Instead of three characters, we could take more as input, which could further improve the loss.

I changed the code slightly, so we have 200,000 steps of optimization. In the first 100,000, we’re using a learning rate of 0.1, and in the next 100,000, we're using a learning rate of 0.01. This is the loss I achieved, and these are the performances on the training and validation loss. The best validation loss I’ve obtained in the last 30 minutes is 2.17. Now, I invite you to beat this number. You have quite a few knobs available to you. You can change the number of neurons in the hidden layer, the dimensionality of the embedding lookup table, the number of characters that are feeding in as input, and the details of the optimization. This includes how long are we running, what is the learning rate, how does it change over time, and how does it decay. You can also change the batch size and may achieve a much better convergence speed. I invite you to read this 19-page paper. At this point, you should be able to understand a good chunk of it, and it has quite a few ideas for improvements. All those are available to you, and you should be able to beat this number. I'm leaving that as an exercise for the reader. That's it for now, and I'll see you next time.

Before we wrap up, I also wanted to show how you would sample from the model. We're going to generate 20 samples. First, we begin with all dots as the context. Until we generate the zeroth character again, we're going to embed the current context using the embedding table. Usually, the first dimension was the size of the training set, but here we are working with a single example, so this is just a dimension of one for simplicity. This embedding gets projected into the end state, and we get the logits. Now, we calculate the probabilities using `f.softmax` of logits. That exponentiates the logits and makes them sum to one. Similar to cross-entropy, it is careful that there are no overflows. Once we have the probabilities, we sample from them using `torch.multinomial` to get our next index. Then, we shift the context window to append the index and record it. We can decode all the integers to strings and print them out. These are some example samples. You can see that the model now works much better. The words here are more word-like or name-like. We have things like "ham joes". It's starting to sound more name-like. We are definitely making progress, but we can still improve this model quite a lot.

There's some bonus content I wanted to mention. I want to make these notebooks more accessible, so you don't have to install Jupyter notebooks and torch. I will be sharing a link to a Google Colab, which will look like a notebook in your browser. You can go to the URL and execute all the code that you saw. This is me executing the code in this lecture, shortened a little. You can train the exact same network and then plot and sample from the model. Everything is ready for you to tinker with the numbers right there in your browser, with no installation necessary. The link to this will be in the video description.
